
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<center>
<head>
	<title> A Neural Network for Detailed Human Depth Estimation from a Single Image </title>
	<link rel="stylesheet" type="text/css" media="screen" href="css/style.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />	
</head>


<body>

<div id="paper-title"> <h1> A Neural Network for Detailed Human Depth Estimation from a Single Image </h1> </div>

<div id="venue">
	ICCV  2019
</div>

<div id="author-list">  
	<a> Sicong Tang<sup>1</sup> </a>
	<a> Feitong Tan<sup>1</sup> </a>
	<a> Kelvin Cheng<sup>1</sup> </a>
	<a> Zhaoyang Li<sup>1</sup> </a>
	<a> Siyu Zhu<sup>2</sup> </a>
	<a> Ping Tan<sup>1</sup> </a>
</div>

<div id="author-affiliation">
	<span class="affiliation"> <sup>1</sup>Simon Fraser University </span>
	<span class="affiliation"> <sup>2</sup>Alibaba AI labs </span>
</div>


<div id="pipeline-part">
	<a class="imageLink" href="./pipeline.png"><img id="pipeline" src="./pipeline.png" alt="Pipeline" width="1100"></a>
</div>

<div id="abstract">
	<h2 class="caption" align="center"> Abstract </h2>
	<p class="paragraph" align="left">  
This paper presents a neural network to estimate a detailed depth map of the foreground human in a single RGB
image. The result captures geometry details such as cloth
wrinkles, which are important in visualization applications.
To achieve this goal, we separate the depth map into a
smooth base shape and a residual detail shape and design
a network with two branches to regress them respectively.
We design a training strategy to ensure both base and detail
shapes can be faithfully learned by the corresponding
network branches. Furthermore, we introduce a novel network
layer to fuse a rough depth map and surface normals
to further improve the final result. Quantitative comparison
with fused ‘ground truth’ captured by real depth cameras
and qualitative examples on unconstrained Internet images
demonstrate the strength of the proposed method.
	</p>
</div>

<div id="package">
	<a id="Paper" href="https://arxiv.org/pdf/1910.01275.pdf"> Paper </a>
	<a id="Code" href="https://github.com/sfu-gruvi-3dv/deep_human">  Code </a>
	<a id="Code" href="https://drive.google.com/file/d/1eQRvwxeMNkWkaX7I3DG4PVOlRiL5ZIne/view?usp=sharing">  Slides  </a>
</div>

<div id="video">
	<h2 class="caption">Supplemental Video </h2>
	<br/>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/ulLpIYHcnCo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<div id="acknowledgement">
	<h2 class="caption"> Acknowledgements </h2>
	<p class="paragraph" align="left"> 
	This work is supported by the NSERC Discovery grant 611664, Discovery Acceleration Supplements 611663, and a research gift from Alibaba AI labs.
	</p>
</div>
<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-98264952-1', 'auto');
  ga('send', 'pageview');

</script>

</body>
</center>
</html>
